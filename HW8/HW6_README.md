# Домашнее задание
Оптимизация работы с Olivetti

Цель:
Цель этого домашнего задания попробовать использование разных классификаторов в качестве Feature Matching.

Описание/Пошаговая инструкция выполнения домашнего задания:
- Взять код из занятия.
- Добавить свою Сеть/Модель в конец.
- Обучить свой классификатор на PCA датасете

# Подход к решению задачи.
В рамках решения задачи я воспользуюсь тем же датасетом c фотографиями 31 селебрити, что и в задаче на использование [лицевых меток](https://www.kaggle.com/datasets/vasukipatel/face-recognition-dataset).

![image](https://github.com/user-attachments/assets/07b3e31e-a419-44c4-a21a-e9b24f5f2427)


Основная задача - это классиифкация лиц, используемые метрики качества - Accuracy и F1.

Задача классификации лиц включает основные этапы:
- детекция лиц
- выраванивание и нормализация
- поиск в базе данных

Решать задачу буду в несколько подходов:
1. Использование готовой библиотеки для классификации лиц. Воспользуюсь библиотекой [DeepFace](https://github.com/serengil/deepface/tree/master) В этой библиотеке реализован весь пайплайн для классификации лиц.
2. Создание векторных представлений изображений с помощью алгоритма кластеризации/уменьшения размерности PCA и использование данных представлений классическими алгоритмами ML и небольщой полносвязной сетью.
3. Создание векторных представлений из модели ResNet с помощью обучения триплетов на Contrastive Loss.

## Сводные результаты экспериментов.

| Алгоритм | Accuracy   | F1    |Ссылка    |
| :---:   | :---: | :---: |:---: |
| Facial Landmarks as Features, CatBoost| 41.05%   | 37.5%| [ноутбук](https://github.com/shakhovak/CV_OTUS_course/blob/master/HW8/HW7_Face_Landmarks_Detectorv4.ipynb)|
| DeepFace, VGG-Face  | 84.6%   |85.97% |[ноутбук](https://github.com/shakhovak/CV_OTUS_course/blob/master/HW8/DeepFace_class.ipynb)|
| PCA, CatBoost  | 61.4%  | 60.58%  |[ноутбук](https://github.com/shakhovak/CV_OTUS_course/blob/master/HW8/HW8_Face_recognition.ipynb)|
| PCA, Dense Net  | 56.73%  | -  |[ноутбук](https://github.com/shakhovak/CV_OTUS_course/blob/master/HW8/HW8_Face_recognition.ipynb)|
| ContrastiveLoss, eucl distance top 10, 1/2 all pos combos  | 87.11%  | 87.25%   |[ноутбук](https://github.com/shakhovak/CV_OTUS_course/blob/master/HW8/triplet_loss_model_train4.ipynb)|
| ContrastiveLoss, Dense Net, 1/2 all pos combos  | 86.73%  | -  |[ноутбук](https://github.com/shakhovak/CV_OTUS_course/blob/master/HW8/triplet_loss_model_train4.ipynb)|
| ContrastiveLoss, SVC, 1/2 all pos combos  | 85.94%  | 80.87%  |[ноутбук](https://github.com/shakhovak/CV_OTUS_course/blob/master/HW8/triplet_loss_model_train4.ipynb)|

## Использование DeepFace
[Ноутбук](https://github.com/shakhovak/CV_OTUS_course/blob/master/HW8/DeepFace_class.ipynb) с решением.  Использование библиотеки достаточно простое, возможен поиск по базе данных изображений. При запуске первого поиска запускается векторизация базы и сохранение ее в формате pkl. Следующие поиски запускается уже по векторизованной базе. Результат по большинству классов неплохой, проблема только в фотографиях нескольких персон. Этот результат возьму за baseline и попробую его превысить :).

![image](https://github.com/user-attachments/assets/4e769590-5020-4677-91c6-873cbcb55ce8)

## Использование PCA
[Ноутбук](https://github.com/shakhovak/CV_OTUS_course/blob/master/HW8/HW8_Face_recognition.ipynb) с решением.
В данном подходе буду использовать рассмотренный на занятии алгоритм снижения размерности вектора изображения с помощью PCA. Основная идея заключается в том, что обучать классификатор можно на сокращенной версии изображений в виде главных компонет. В рамках данного решения я уже буду в вырезанными из основного датасета изображениями лиц и приведенными к общей размерности. 
> [!IMPORTANT]
> Получается не совсем честной преимущество при сравнении с DeepFace, так как точность детекции лица здесь = 100%!!!

![image](https://github.com/user-attachments/assets/cbfba114-dbb4-45f8-8dc9-c5d4523e1b80)

Неплохие результаты дают экперименты с 150-200 компонентами, однако несмотря на нечестное преимущество результаты все равно хуже :(.

## Обучение на Contrastive Loss
[Ноутбук](https://github.com/shakhovak/CV_OTUS_course/blob/master/HW8/triplet_loss_model_train4.ipynb) с решением.
В данном подходе для классификации лиц будут использовать эмбеддинги, полученные от ResNet18 при обучении на Contrastive Loss, который штрафует за увеличение косинусного расстояния между похожими объектами. Оцениваются эмбеддингы с помощью классификации на тестовой выборке: 
- путем выборки из обучающих данных векторов, которые имеют наименьшее расстояние с тестовыми данными
- использование векторов в качестве фичей для полносвязной сети
- использованием векторов в качестве фичей для SVM
Будут также использованы вырезанные изображения лиц как и для PCA экспериментов.

# Выводы:
Использование эмббедингов из ResNet18, обученной на Contrastive Loss показало лучшие результаты, сопоставимые с готовой библиотекой (пусть и не совсем честные). При этом была использована только половина все возможных положительных комбинаций, соответсвенно есть потенциал для улучшения модели.
